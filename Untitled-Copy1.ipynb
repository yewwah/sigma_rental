{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json\n",
    "import seaborn as sb \n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import linear_model \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import zscore\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimators = [300]\n",
    "learning = [0.3,0.4,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_json('data/train.json', encoding = 'utf-8', dtype = {'description': str})\n",
    "len(df)\n",
    "df = df[:20000]\n",
    "#df = df[['description', 'interest_level']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>building_id</th>\n",
       "      <th>created</th>\n",
       "      <th>description</th>\n",
       "      <th>display_address</th>\n",
       "      <th>features</th>\n",
       "      <th>interest_level</th>\n",
       "      <th>latitude</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>manager_id</th>\n",
       "      <th>photos</th>\n",
       "      <th>price</th>\n",
       "      <th>street_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>53a5b119ba8f7b61d4e010512e0dfc85</td>\n",
       "      <td>2016-06-24 07:54:24</td>\n",
       "      <td>A Brand New 3 Bedroom 1.5 bath ApartmentEnjoy ...</td>\n",
       "      <td>Metropolitan Avenue</td>\n",
       "      <td>[]</td>\n",
       "      <td>medium</td>\n",
       "      <td>40.7145</td>\n",
       "      <td>7211212</td>\n",
       "      <td>-73.9425</td>\n",
       "      <td>5ba989232d0489da1b5f2c45f6688adc</td>\n",
       "      <td>[https://photos.renthop.com/2/7211212_1ed4542e...</td>\n",
       "      <td>3000</td>\n",
       "      <td>792 Metropolitan Avenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>c5c8a357cba207596b04d1afd1e4f130</td>\n",
       "      <td>2016-06-12 12:19:27</td>\n",
       "      <td></td>\n",
       "      <td>Columbus Avenue</td>\n",
       "      <td>[Doorman, Elevator, Fitness Center, Cats Allow...</td>\n",
       "      <td>low</td>\n",
       "      <td>40.7947</td>\n",
       "      <td>7150865</td>\n",
       "      <td>-73.9667</td>\n",
       "      <td>7533621a882f71e25173b27e3139d83d</td>\n",
       "      <td>[https://photos.renthop.com/2/7150865_be3306c5...</td>\n",
       "      <td>5465</td>\n",
       "      <td>808 Columbus Avenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>c3ba40552e2120b0acfc3cb5730bb2aa</td>\n",
       "      <td>2016-04-17 03:26:41</td>\n",
       "      <td>Top Top West Village location, beautiful Pre-w...</td>\n",
       "      <td>W 13 Street</td>\n",
       "      <td>[Laundry In Building, Dishwasher, Hardwood Flo...</td>\n",
       "      <td>high</td>\n",
       "      <td>40.7388</td>\n",
       "      <td>6887163</td>\n",
       "      <td>-74.0018</td>\n",
       "      <td>d9039c43983f6e564b1482b273bd7b01</td>\n",
       "      <td>[https://photos.renthop.com/2/6887163_de85c427...</td>\n",
       "      <td>2850</td>\n",
       "      <td>241 W 13 Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100007</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28d9ad350afeaab8027513a3e52ac8d5</td>\n",
       "      <td>2016-04-18 02:22:02</td>\n",
       "      <td>Building Amenities - Garage - Garden - fitness...</td>\n",
       "      <td>East 49th Street</td>\n",
       "      <td>[Hardwood Floors, No Fee]</td>\n",
       "      <td>low</td>\n",
       "      <td>40.7539</td>\n",
       "      <td>6888711</td>\n",
       "      <td>-73.9677</td>\n",
       "      <td>1067e078446a7897d2da493d2f741316</td>\n",
       "      <td>[https://photos.renthop.com/2/6888711_6e660cee...</td>\n",
       "      <td>3275</td>\n",
       "      <td>333 East 49th Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100013</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-28 01:32:41</td>\n",
       "      <td>Beautifully renovated 3 bedroom flex 4 bedroom...</td>\n",
       "      <td>West 143rd Street</td>\n",
       "      <td>[Pre-War]</td>\n",
       "      <td>low</td>\n",
       "      <td>40.8241</td>\n",
       "      <td>6934781</td>\n",
       "      <td>-73.9493</td>\n",
       "      <td>98e13ad4b495b9613cef886d79a6291f</td>\n",
       "      <td>[https://photos.renthop.com/2/6934781_1fa4b41a...</td>\n",
       "      <td>3350</td>\n",
       "      <td>500 West 143rd Street</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bathrooms  bedrooms                       building_id  \\\n",
       "10            1.5         3  53a5b119ba8f7b61d4e010512e0dfc85   \n",
       "10000         1.0         2  c5c8a357cba207596b04d1afd1e4f130   \n",
       "100004        1.0         1  c3ba40552e2120b0acfc3cb5730bb2aa   \n",
       "100007        1.0         1  28d9ad350afeaab8027513a3e52ac8d5   \n",
       "100013        1.0         4                                 0   \n",
       "\n",
       "                    created  \\\n",
       "10      2016-06-24 07:54:24   \n",
       "10000   2016-06-12 12:19:27   \n",
       "100004  2016-04-17 03:26:41   \n",
       "100007  2016-04-18 02:22:02   \n",
       "100013  2016-04-28 01:32:41   \n",
       "\n",
       "                                              description  \\\n",
       "10      A Brand New 3 Bedroom 1.5 bath ApartmentEnjoy ...   \n",
       "10000                                                       \n",
       "100004  Top Top West Village location, beautiful Pre-w...   \n",
       "100007  Building Amenities - Garage - Garden - fitness...   \n",
       "100013  Beautifully renovated 3 bedroom flex 4 bedroom...   \n",
       "\n",
       "            display_address  \\\n",
       "10      Metropolitan Avenue   \n",
       "10000       Columbus Avenue   \n",
       "100004          W 13 Street   \n",
       "100007     East 49th Street   \n",
       "100013    West 143rd Street   \n",
       "\n",
       "                                                 features interest_level  \\\n",
       "10                                                     []         medium   \n",
       "10000   [Doorman, Elevator, Fitness Center, Cats Allow...            low   \n",
       "100004  [Laundry In Building, Dishwasher, Hardwood Flo...           high   \n",
       "100007                          [Hardwood Floors, No Fee]            low   \n",
       "100013                                          [Pre-War]            low   \n",
       "\n",
       "        latitude  listing_id  longitude                        manager_id  \\\n",
       "10       40.7145     7211212   -73.9425  5ba989232d0489da1b5f2c45f6688adc   \n",
       "10000    40.7947     7150865   -73.9667  7533621a882f71e25173b27e3139d83d   \n",
       "100004   40.7388     6887163   -74.0018  d9039c43983f6e564b1482b273bd7b01   \n",
       "100007   40.7539     6888711   -73.9677  1067e078446a7897d2da493d2f741316   \n",
       "100013   40.8241     6934781   -73.9493  98e13ad4b495b9613cef886d79a6291f   \n",
       "\n",
       "                                                   photos  price  \\\n",
       "10      [https://photos.renthop.com/2/7211212_1ed4542e...   3000   \n",
       "10000   [https://photos.renthop.com/2/7150865_be3306c5...   5465   \n",
       "100004  [https://photos.renthop.com/2/6887163_de85c427...   2850   \n",
       "100007  [https://photos.renthop.com/2/6888711_6e660cee...   3275   \n",
       "100013  [https://photos.renthop.com/2/6934781_1fa4b41a...   3350   \n",
       "\n",
       "                 street_address  \n",
       "10      792 Metropolitan Avenue  \n",
       "10000       808 Columbus Avenue  \n",
       "100004          241 W 13 Street  \n",
       "100007     333 East 49th Street  \n",
       "100013    500 West 143rd Street  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10              Metropolitan \n",
       "10000               Columbus \n",
       "100004                  W 13 \n",
       "100007             East 49th \n",
       "100013            West 143rd \n",
       "100014             West 18th \n",
       "100016            West 107th \n",
       "100020             West 21st \n",
       "100026       Hamilton Terrace\n",
       "100027             522 E 11th\n",
       "100030                  York \n",
       "10004               W. 173rd \n",
       "100044              E 38th St\n",
       "100048             West 63rd \n",
       "10005          East 56th St..\n",
       "100051             East 34th \n",
       "100052               1st Ave.\n",
       "100053              Thayer St\n",
       "100055            West 106th \n",
       "100058                   1st \n",
       "100062               Madison \n",
       "100063             E 30th St,\n",
       "100065             East 35th \n",
       "100066               Liberty \n",
       "10007                W 18 St.\n",
       "100071              East 56th\n",
       "100075             E 81st St.\n",
       "100076             West 57th \n",
       "100079           1215 Morris \n",
       "100081             E 79th St.\n",
       "                 ...         \n",
       "33553     E 55th & Second Ave\n",
       "3356              William St.\n",
       "33562              Waverly Pl\n",
       "33565       Central Park West\n",
       "33566                 Rockne \n",
       "33567              West 34th \n",
       "33568                    e 25\n",
       "33570              Greenwich \n",
       "33577          260 West 26th \n",
       "33578           10 West 87th \n",
       "33579                Broadway\n",
       "3358               W 20th St.\n",
       "33581                W 65 St.\n",
       "33584               Columbus \n",
       "33586                W 43 St.\n",
       "33588              E 19th St.\n",
       "33595                W 56 St.\n",
       "33597              East 89th \n",
       "33598                   W 47 \n",
       "33599            audubon ave \n",
       "336            Edgecombe Ave.\n",
       "3360               East 61st \n",
       "33600              Park Place\n",
       "33601          Hell's Kitchen\n",
       "33603                   Gold \n",
       "33605                 Wall st\n",
       "33608            williamsburg\n",
       "33609           Battery Place\n",
       "33610                W 62 St.\n",
       "33612            williamsburg\n",
       "Name: new, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['new'] = df['display_address'].apply(lambda x: x.replace('Street', '').replace('Avenue', ''))\n",
    "df['new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dual': True, 'loss': 'hinge'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(loss = 'hinge', dual = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transformers.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[self._column] = df[self._column].apply(lambda x : ' '.join(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-bd11119833a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'finished training'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m#loss = logloss(pred, test_labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "#pg = dict(clf__verbose = ['True'])\n",
    "pg = {'clf__learning_rate' : learning, 'clf__n_estimators' : estimators}\n",
    "\n",
    "import xgboost\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from Transformers import TextTransformer, ColumnExtractor\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "a = TextTransformer('description', max_features=3000)\n",
    "b = TextTransformer('features', max_features=3000)\n",
    "c = TextTransformer('street_address', max_features = 3000)\n",
    "d = TextTransformer('display_address', max_features = 3000)\n",
    "pipeline = Pipeline([\n",
    "        ('test', FeatureUnion\n",
    "         ([\n",
    "            ('description', a ), # can pass in either a pipeline\n",
    "            ('features', b),\n",
    "            ('street', c),\n",
    "            ('display', d),\n",
    "            ('lat_long', ColumnExtractor(['latitude', 'longitude']))\n",
    "        ])),\n",
    "    ('clf',xgboost.XGBClassifier(silent = False))\n",
    "    ])\n",
    "for train_index, test_index in skf.split(df, df['interest_level']):\n",
    "    print 'starting code'\n",
    "    train, train_labels = df.iloc[train_index], df['interest_level'].iloc[train_index]\n",
    "    test, test_labels = df.iloc[test_index], df['interest_level'].iloc[test_index]\n",
    "    pred = pipeline.fit(train,train_labels)\n",
    "    print 'finished training'\n",
    "    pred = (pred.predict_proba(test))\n",
    "    \n",
    "    #loss = logloss(pred, test_labels)\n",
    "    sklearn_loss = log_loss(test_labels, pred)\n",
    "    print 'Log loss from sklearn', sklearn_loss\n",
    "#scores = cross_val_score(pipeline, df, df['interest_level'], cv=2)\n",
    "#regr = \n",
    "#search = GridSearchCV(regr, param_grid, scoring = 'neg_log_loss', n_jobs = -1)\n",
    "#pg = {'clf__C': [0.1,0.2]}\n",
    "\n",
    "#print pipeline.get_params().keys()\n",
    "#grid = GridSearchCV(pipeline, param_grid = pg, cv = 2, verbose = 10)\n",
    "#grid.fit(df, df['interest_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_transform(content_lst):\n",
    "    return ' '.join(content_lst)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "param_grid = dict(learning_rate = learning, n_estimators = estimators)\n",
    "for train_index, test_index in skf.split(df_cleaned, df_target):\n",
    "    print 'starting code'\n",
    "    train, train_labels = df_cleaned.iloc[train_index], df_target.iloc[train_index]\n",
    "    tf_transformer = TfidfVectorizer(use_idf=False,  stop_words = 'english', \n",
    "                                     tokenizer = custom_tokenizer, analyzer = 'word', max_features = 5000)\n",
    "    tf_transformer_features = TfidfVectorizer(use_idf=False,  stop_words = 'english', \n",
    "                                     tokenizer = custom_tokenizer, analyzer = 'word', max_features = 3000)\n",
    "    \n",
    "    train_bow = tf_transformer.fit_transform(train['description'])\n",
    "    train = train.drop(['description'], axis = 1)\n",
    "    train_bow_features = tf_transformer_features.fit_transform(train['features'])\n",
    "    train = train.drop(['features'], axis = 1)\n",
    "    train_bow = pd.DataFrame(train_bow.todense())\n",
    "    names = [str(x) for x in range(5000,5000 + train_bow_features.shape[1])]\n",
    "    train_bow_features = pd.DataFrame(train_bow_features.todense())\n",
    "    train_bow_features.columns = names\n",
    "    \n",
    "    train = train.join(train_bow)\n",
    "    train = train.join(train_bow_features)\n",
    "    train.fillna(0, inplace = True)\n",
    "    print train.shape\n",
    "    print 'Building the model'\n",
    "     \n",
    "    test, test_labels = df_cleaned.iloc[test_index], df_target.iloc[test_index]\n",
    "    test_bow = tf_transformer.transform(test['description'])\n",
    "    test_bow = pd.DataFrame(test_bow.todense())\n",
    "    test_bow_features = tf_transformer_features.transform(test['features'])\n",
    "    test_bow_features = pd.DataFrame(test_bow_features.todense())\n",
    "    test_bow_features.columns = names\n",
    "    test = test.drop(['description'], axis = 1)\n",
    "    test = test.drop(['features'], axis = 1)\n",
    "     \n",
    "    #train.fillna('0', inplace = True)\n",
    "    test = test.join(test_bow)\n",
    "    test = test.join(test_bow_features)\n",
    "    eval_set = [(train, train_labels), (test, test_labels)]\n",
    "    regr = xgboost.XGBClassifier(silent = False)\n",
    "    search = GridSearchCV(regr, param_grid, scoring = 'neg_log_loss', n_jobs = -1)\n",
    "    res = search.fit(train, train_labels)\n",
    "    results.append(res)\n",
    "\n",
    "    #regr.fit(train, train_labels, eval_metric = 'mlogloss', eval_set = eval_set, verbose = True)\n",
    "    \n",
    "    \n",
    "    #test.fillna('0', inplace = True)\n",
    "    #regr = linear_model.LogisticRegression(class_weight = 'balanced', probability = True)\n",
    "\n",
    "    print 'finished training'\n",
    "    pred = (res.predict_proba(test))\n",
    "    \n",
    "    #loss = logloss(pred, test_labels)\n",
    "    sklearn_loss = log_loss(test_labels, pred)\n",
    "    print 'Log loss from sklearn', sklearn_loss\n",
    "    \n",
    "    #print confusion_matrix(pred, test_labels)\n",
    "    #print accuracy_score(pred, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for train_index, test_index in skf.split(df_cleaned, df_target):\n",
    "    print 'starting code'\n",
    "    train, train_labels = df_cleaned.iloc[train_index], df_target.iloc[train_index]\n",
    "    tf_transformer = TfidfVectorizer(use_idf=False,  stop_words = 'english', \n",
    "                                     tokenizer = custom_tokenizer, analyzer = 'word', max_features = 5000)\n",
    "    tf_transformer_features = TfidfVectorizer(use_idf=False,  stop_words = 'english', \n",
    "                                     tokenizer = custom_tokenizer, analyzer = 'word', max_features = 3000)\n",
    "    \n",
    "    train_bow = tf_transformer.fit_transform(train['description'])\n",
    "    train = train.drop(['description'], axis = 1)\n",
    "    train_bow_features = tf_transformer_features.fit_transform(train['features'])\n",
    "    train = train.drop(['features'], axis = 1)\n",
    "    train_bow = pd.DataFrame(train_bow.todense())\n",
    "    names = [str(x) for x in range(5000,5000 + train_bow_features.shape[1])]\n",
    "    train_bow_features = pd.DataFrame(train_bow_features.todense())\n",
    "    train_bow_features.columns = names\n",
    "    \n",
    "    train = train.join(train_bow)\n",
    "    train = train.join(train_bow_features)\n",
    "    train.fillna(0, inplace = True)\n",
    "    print train.shape\n",
    "    print 'Building the model'\n",
    "     \n",
    "    test, test_labels = df_cleaned.iloc[test_index], df_target.iloc[test_index]\n",
    "    test_bow = tf_transformer.transform(test['description'])\n",
    "    test_bow = pd.DataFrame(test_bow.todense())\n",
    "    test_bow_features = tf_transformer_features.transform(test['features'])\n",
    "    test_bow_features = pd.DataFrame(test_bow_features.todense())\n",
    "    test_bow_features.columns = names\n",
    "    test = test.drop(['description'], axis = 1)\n",
    "    test = test.drop(['features'], axis = 1)\n",
    "     \n",
    "    #train.fillna('0', inplace = True)\n",
    "    test = test.join(test_bow)\n",
    "    test = test.join(test_bow_features)\n",
    "    eval_set = [(train, train_labels), (test, test_labels)]\n",
    "    regr = xgboost.XGBClassifier(n_estimators  = 300, silent = False)\n",
    "    regr.fit(train, train_labels, eval_metric = 'mlogloss', eval_set = eval_set, verbose = True)\n",
    "    \n",
    "    \n",
    "    #test.fillna('0', inplace = True)\n",
    "    #regr = linear_model.LogisticRegression(class_weight = 'balanced', probability = True)\n",
    "\n",
    "    print 'finished training'\n",
    "    pred = (regr.predict_proba(test))\n",
    "    \n",
    "    #loss = logloss(pred, test_labels)\n",
    "    sklearn_loss = log_loss(test_labels, pred)\n",
    "    print 'Log loss from sklearn', sklearn_loss\n",
    "    \n",
    "    #print confusion_matrix(pred, test_labels)\n",
    "    #print accuracy_score(pred, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_json('data/test.json')\n",
    "listing_ids = test_df['listing_id']\n",
    "test_df['description'] = test_df['description'].apply(clean_html_tags)\n",
    "test_df = test_df[['bathrooms', 'bedrooms', 'latitude', 'longitude', 'price', 'description', 'features']]\n",
    "test_df['description'] = test_df['description'].astype(unicode)\n",
    "test_df['features'] = test_df['features'].astype(unicode)\n",
    "test_df_bow = tf_transformer.transform(test_df['description'])\n",
    "test_df_bow = pd.DataFrame(test_df_bow.todense())\n",
    "test_df = test_df.drop(['description'], axis = 1)\n",
    "test_df_bow_features = tf_transformer_features.transform(test_df['features'])\n",
    "test_df_bow_features = pd.DataFrame(test_df_bow_features.todense())\n",
    "test_df_bow_features.columns = names\n",
    "test_df = test_df.drop(['features'], axis = 1)\n",
    "test_df = test_df.join(test_df_bow)\n",
    "test_df = test_df.join(test_df_bow_features)\n",
    "    \n",
    "pred = regr.predict_proba(test_df)\n",
    "\n",
    "pred = pd.DataFrame(pred, columns = ['high', 'medium', 'low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred['listing_id'] = listing_ids.values\n",
    "pred = pred[['listing_id', 'high', 'medium', 'low']]\n",
    "pred.to_csv('test_raw_xgboost.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = regr.evals_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = len(results['validation_0']['mlogloss'])\n",
    "x_axis = range(0, epochs)\n",
    "\n",
    "\n",
    "pyplot.plot(x_axis, results['validation_0']['mlogloss'], label='Train')\n",
    "\n",
    "pyplot.plot(x_axis, results['validation_1']['mlogloss'], label='Test')\n",
    "pyplot.legend()\n",
    "pyplot.xlabel('epochs')\n",
    "pyplot.ylabel('Log Loss')\n",
    "pyplot.title('XGBoost Log Loss')\n",
    "pyplot.show()\n",
    "# plot classification error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=================================================\n",
    "Concatenating multiple feature extraction methods\n",
    "=================================================\n",
    "\n",
    "In many real-world examples, there are many ways to extract features from a\n",
    "dataset. Often it is beneficial to combine several methods to obtain good\n",
    "performance. This example shows how to use ``FeatureUnion`` to combine\n",
    "features obtained by PCA and univariate selection.\n",
    "\n",
    "Combining features using this transformer has the benefit that it allows\n",
    "cross validation and grid searches over the whole process.\n",
    "\n",
    "The combination used in this example is not particularly helpful on this\n",
    "dataset and is only used to illustrate the usage of FeatureUnion.\n",
    "\"\"\"\n",
    "\n",
    "# Author: Andreas Mueller <amueller@ais.uni-bonn.de>\n",
    "#\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X, y = iris.data, iris.target\n",
    "print iris.data\n",
    "# This dataset is way too high-dimensional. Better do PCA:\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Maybe some original features where good, too?\n",
    "selection = SelectKBest(k=1)\n",
    "\n",
    "# Build estimator from PCA and Univariate selection:\n",
    "\n",
    "combined_features = FeatureUnion([(\"pca\", pca), (\"univ_select\", selection)])\n",
    "\n",
    "# Use combined features to transform dataset:\n",
    "X_features = combined_features.fit(X, y).transform(X)\n",
    "\n",
    "svm = SVC(kernel=\"linear\")\n",
    "\n",
    "# Do grid search over k, n_components and C:\n",
    "\n",
    "pipeline = Pipeline([(\"features\", combined_features), (\"svm\", svm)])\n",
    "\n",
    "#param_grid = dict(features__pca__n_components=[1, 2, 3],\n",
    "                  #features__univ_select__k=[1, 2],\n",
    "                  #svm__C=[0.1, 1, 10])\n",
    "pipeline.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "\n",
    "\n",
    "class TextTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,col, max_features = 10):\n",
    "        self.tfidfVectorizer = TfidfVectorizer(use_idf=False, stop_words='english',\n",
    "                                               tokenizer=self._custom_tokenizer, analyzer='word',\n",
    "                                               max_features=max_features)\n",
    "        self._vectorizer = None\n",
    "        self._column = 'description'\n",
    "\n",
    "    def _custom_tokenizer(self, string):\n",
    "        # string = re.sub('^[\\w]', '', string)\n",
    "        tokens = nltk.word_tokenize(string)\n",
    "        cleaned = [x if not x.isdigit() else '_NUM_' for x in tokens]\n",
    "        return [str(x.encode('utf-8')) for x in cleaned if (x.isalpha() or x == '_NUM_')]\n",
    "\n",
    "    def _clean_html_tags(self, content):\n",
    "        return BeautifulSoup(content, 'lxml').text\n",
    "\n",
    "    def fit(self, df, y = None):\n",
    "        self._vectorizer = self.tfidfVectorizer.fit(df[self._column].apply(self._clean_html_tags))\n",
    "        return self\n",
    "\n",
    "    def transform(self, df, y=None):\n",
    "        return self._vectorizer.transform(df[self._column]).todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_json('data/train.json', encoding = 'utf-8', dtype = {'description': str})\n",
    "len(df)\n",
    "#df = df[['description', 'interest_level']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "a = TextTransformer('testing')\n",
    "b = TextTransformer('features', max_features=10)\n",
    "a = FeatureUnion([(\"pca\", a), ('test', b)])\n",
    "pipe = Pipeline([('description', a)])\n",
    "X = df\n",
    "y = df['interest_level'].values\n",
    "pipe.fit(X,y)\n",
    "# pg = {'clf__C': [0.1,1]}\n",
    "# grid = GridSearchCV(pipeline, param_grid= pg ,cv = 2)\n",
    "# grid.fit(df, df['interest_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = df[['latitude', 'longitude', 'interest_level']]\n",
    "a['interest_level'] = a['interest_level'].apply(repl)\n",
    "#a = a.pivot_table('latitude', 'longitude', 'interest_level', aggfunc='sum')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_lat = np.max(df['latitude'])\n",
    "min_lat = np.min(df['latitude'])\n",
    "mean = np.mean(df['latitude'])\n",
    "std =  np.std(df['latitude'])\n",
    "width = 3 * std\n",
    "(n, bin, patch) = plt.hist(df['latitude'], bins = [min_lat, mean - width, mean , mean + width, max_lat])\n",
    "print n \n",
    "print bin\n",
    "print patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = df[['latitude', 'longitude', 'interest_level']]\n",
    "df1.head\n",
    "df2 = df1[df1['latitude'] >41]\n",
    "sns.boxplot(y=df2['latitude'], data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.lmplot('latitude', 'longitude', data = df1, hue = 'interest_level', fit_reg = False, size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = df1[ (df1['longitude'] > -74.1) & (df1['longitude'] <-73.8)]\n",
    "df1 = df1[(df1['latitude'] > 40.5) & (df1['latitude'] <40.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def repl(label):\n",
    "    if label == 'low':\n",
    "        return 1\n",
    "    elif label == 'medium':\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['latitude'] = pd.cut(df['latitude'], 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['longitude'] = pd.cut(df['longitude'], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
