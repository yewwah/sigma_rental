{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json\n",
    "import seaborn as sb \n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import linear_model \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import zscore\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from string import ascii_letters\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49352"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('data/train.json', encoding = 'utf-8', dtype = {'description': str})\n",
    "print df['description'].dtype\n",
    "df.head()\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_html_tags(content):\n",
    "    return BeautifulSoup(content, 'lxml').text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_tokenizer(string):\n",
    "    #string = re.sub('^[\\w]', '', string)\n",
    "    tokens = nltk.word_tokenize(string)\n",
    "    cleaned = [x if not x.isdigit() else '_NUM_' for x in tokens]\n",
    "    return [str(x.encode('utf-8')) for x in cleaned if (x.isalpha() or x == '_NUM_')]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \".\" looks like a filename, not markup. You shouldprobably open this file and pass the filehandle intoBeautiful Soup.\n",
      "  'Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "df['description'] = df['description'].apply(clean_html_tags)\n",
    "count_vect = CountVectorizer(tokenizer = custom_tokenizer, stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_target = df['interest_level']\n",
    "#df = df.drop(['interest_level'], axis = 1)\n",
    "df_cleaned = df[['bathrooms', 'bedrooms', 'latitude', 'longitude', 'price', 'description']]\n",
    "df_cleaned['description'] = df['description'].astype(unicode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting code\n",
      "(39481, 1000)\n",
      "(39481, 5)\n",
      "(39481, 1005)\n",
      "        bathrooms  bedrooms  latitude  longitude  price    0    1    2    3  \\\n",
      "122211        2.0         2   40.7173   -73.9537   5075  0.0  0.0  0.0  0.0   \n",
      "122216        1.0         0   40.7479   -73.9739   2550  0.0  0.0  0.0  0.0   \n",
      "122219        2.0         2   40.7656   -73.9857   4250  0.0  0.0  0.0  0.0   \n",
      "122220        2.0         3   40.8274   -73.9514   4475  0.0  0.0  0.0  0.0   \n",
      "122221        1.0         0   40.7034   -74.0095   2700  0.0  0.0  0.0  0.0   \n",
      "\n",
      "          4 ...   990  991  992  993  994  995  996  997  998  999  \n",
      "122211  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "122216  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "122219  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "122220  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "122221  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 1005 columns]\n",
      "Building the model\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in skf.split(df_cleaned, df_target):\n",
    "    print 'starting code'\n",
    "    train, train_labels = df_cleaned.iloc[train_index], df_target.iloc[train_index]\n",
    "    tf_transformer = TfidfVectorizer(use_idf=False,  stop_words = 'english', tokenizer = custom_tokenizer, analyzer = 'word', max_features = 1000)\n",
    "    train_bow = tf_transformer.fit_transform(train['description'])\n",
    "    train = train.drop(['description'], axis = 1)\n",
    "    train_bow = pd.DataFrame(train_bow.todense())\n",
    "    train_bow.fillna(0, inplace = True)\n",
    "    print train_bow.shape\n",
    "    \n",
    "    print train.shape\n",
    "    train = train.join(train_bow)\n",
    "    train.fillna(0, inplace = True)\n",
    "    print train.shape\n",
    "    print train.head()\n",
    "    print 'Building the model'\n",
    "    regr = SVC(kernel = 'linear', probability = True, C = 1, class_weight = 'balanced')\n",
    "    regr.fit(train, train_labels)\n",
    "    \n",
    "    del train\n",
    "    \n",
    "    test, test_labels = df_cleaned.iloc[test_index], df_target.iloc[test_index]\n",
    "    test = test.drop(['description'], axis = 1)\n",
    "    test_bow = tf_transformer.transform(test['description'])\n",
    "    test_bow = pd.DataFrame(test_bow.todense())\n",
    "    \n",
    "    #train.fillna('0', inplace = True)\n",
    "    test = pd.concat((test,test_bow))\n",
    "    #test.fillna('0', inplace = True)\n",
    "    #regr = linear_model.LogisticRegression(class_weight = 'balanced', probability = True)\n",
    "\n",
    "    print 'finished training'\n",
    "    pred = (regr.predict_proba(test))\n",
    "    \n",
    "    #loss = logloss(pred, test_labels)\n",
    "    sklearn_loss = log_loss(test_labels, pred)\n",
    "    print 'Log loss from sklearn', sklearn_loss\n",
    "    break\n",
    "    #print confusion_matrix(pred, test_labels)\n",
    "    #print accuracy_score(pred, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenizer(string):\n",
    "    #string = re.sub('^[\\w]', '', string)\n",
    "    tokens = nltk.word_tokenize(string)\n",
    "    cleaned = [x if not x.isdigit() else '_NUM_' for x in tokens]\n",
    "    return [x.encode('utf-8') for x in cleaned if (x.isalpha() or x == '_NUM_')]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
